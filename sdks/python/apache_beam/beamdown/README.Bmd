<!--
    Licensed to the Apache Software Foundation (ASF) under one
    or more contributor license agreements.  See the NOTICE file
    distributed with this work for additional information
    regarding copyright ownership.  The ASF licenses this file
    to you under the Apache License, Version 2.0 (the
    "License"); you may not use this file except in compliance
    with the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on an
    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.
-->

# Beamdown: Literate Programming for Beam

Beamdown aims to help users create more readable literate pipeline by leveraging
the advantages of the new lightweight YAML interface included in the Python Beam
SDK.

## Defining Blocks

The basic element of Beamdown processing is the transform block, which lets you
define a transform just like you would in a a YAML pipeline. The main thing to
note here is that you define the type of block as well as give it a name.

Using the same example as YAML's README.md we define two blocks to read and
write. Note that we also have access to the Jinja macro language inside of our
Markdown file, which lets us parameterize our documents easily!

Here's the graph we are going to make
```mermaid
{{ graph('mermaid') }}
```

We start reading CSV data from the ```input_files``` parameter.

```{.yaml .source #csv-read}
type: ReadFromCsv
path: {{ args.input_files }}
```

We are eventually going to write them as JSON specified by ```output_path```. Note that the inputs are defined in the block definition.

```{.yaml .sink #json-write inputs=my-first-filter}
type: WriteToJson
path: {{ args.output_path }}
```

In this example we are using the YAML specification to handle the inputs (in this case an array of input names).

```{.yaml #flatten-test}
type: Flatten
input: [csv-read,my-first-filter]
```

To make writing code a little easier, we also define two other types of blocks
in Beamdown (though you can add even more block types with a planned plugin
functionality). The first are Python blocks, which help to make writing Python
more clear.

```{.python .filter #my-first-filter inputs=csv-read}
def myfilter(x): 
    x.col3 > 100
```

We can do the same thing with SQL!
```{.sql #my-sql}
SELECT col1, COUNT(*) AS cnt FROM {{ ref('my-first-filter') }} GROUP BY col1
```

Make sure we have some extras....
